{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as dt\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and Hyperparameters #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./US_length.csv\"\n",
    "learning_rate = 0.00001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "split = 0.8\n",
    "batch_size = 100\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChuckDaddy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_main = pd.read_csv(data_path, sep = ',')\n",
    "#subset data for testing ,use the first 10000\n",
    "df = df_main[:10000]\n",
    "secs = df['sec'].values\n",
    "mins = df['min'].values\n",
    "hours = df['hour'].values\n",
    "total_time = [s+60*m+3600*h for s,m,h in zip(secs, mins, hours)]\n",
    "df['total_time'] = total_time\n",
    "df_features=df[['title', 'total_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChuckDaddy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ChuckDaddy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\ChuckDaddy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_features['title_upper_count'] = df_features['title'].str.findall(r'[A-Z]').str.len()\n",
    "df_features['tag_count'] = [len(s.split('|')) for s in df['tags'].values]\n",
    "df_features['category_id'] = df_main['category_id']\n",
    "df_label = pd.DataFrame()\n",
    "df_label['views'] = df['views']\n",
    "df_features = df_features.drop(columns = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time</th>\n",
       "      <th>title_upper_count</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>678</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1431</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>569</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>430</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_time  title_upper_count  tag_count  category_id\n",
       "0         678                 28          1           22\n",
       "1        1431                 11          4           24\n",
       "2         569                  8         23           23\n",
       "3         430                  4         27           24\n",
       "4         733                 12         14           24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>748374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2418783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3191434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2095731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     views\n",
       "0   748374\n",
       "1  2418783\n",
       "2  3191434\n",
       "3   343168\n",
       "4  2095731"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head()\n",
    "# def to_list(val):\n",
    "#     return [val]\n",
    "# df_label['views'] = df_label['views'].apply(to_list)\n",
    "# df_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Dataloader #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_split = int(len(df_features)*split)\n",
    "train_set = df_features[:tv_split]\n",
    "train_label = df_label[:tv_split]\n",
    "validation_set = df_features[tv_split:]\n",
    "validation_label = df_label[tv_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(dt.Dataset):\n",
    "    def __init__(self, feature, labels):\n",
    "        self.labels = labels\n",
    "        self.feature = feature\n",
    "    def __len__(self):\n",
    "        return(len(self.feature))\n",
    "    def __getitem__(self, idx):\n",
    "        cur_feature = self.feature.iloc[idx]\n",
    "        cur_feature = np.array(cur_feature)\n",
    "        cur_label = self.labels.iloc[idx]\n",
    "        cur_label = np.array(cur_label)\n",
    "        sample = (cur_feature, cur_label)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Dataset(train_set, train_label)\n",
    "test_loader = Dataset(validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size).double() \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes).double()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3821e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.7202e-12], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.4288e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.9599e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.9093e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.6100e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.4728e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0012], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0018], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0028], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0028], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.9634e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0589], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0101], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0057], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.6342e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0026], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0046], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0033], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0063], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.9080e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0237], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.5345e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0087], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1932], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.3652e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0625], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0015], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0001], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1014], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0863], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.5754e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0019], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0065], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0012], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0033], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0681], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1430], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.5130e-12], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0066], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1225], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1186], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.1103e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.7340e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0044], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0016], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.4589e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0288], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0011], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0515], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0245], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0306], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.9582e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0168], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0589], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0041], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0050], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0527], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.3679e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0023], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0596], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0746], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0018], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.9422e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.8686e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0221e-24], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0022], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0037], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0168], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0042], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0208], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0898], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.4411e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.8812e-11], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0227], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.1491e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0552], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0019], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0550], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0032], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.9608e-162], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0256], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.], device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0488], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.9022e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0067], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0465], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0001], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0043], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "Epoch [1/1], Step [100/8000], Loss: 195684.4957\n",
      "tensor([0.0016], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0007], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0013], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0825], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.6764e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.4245e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0009], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0095], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0026], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0013], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0067], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0007], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0026], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.1217e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1982], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0013], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.1367e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0013], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3349e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.1267e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0152], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.5536e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0544], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0512], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.8326e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.2447e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0025], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0035], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0053], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0483], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.9099e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0074], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0025], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0307], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0688], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0647], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0091], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0063], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0028], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.3642e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0650], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.6221e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.5856e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0045], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0296], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0372], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0035], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.0605e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0544], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.5615e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0063], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.6506e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0714], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.5748e-15], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0022], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0516], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0138], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0780], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0012], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0160], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.2065], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0040], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.1891e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.8028e-11], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.8781e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.9352e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0634], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0382], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0673], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0346], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.1253e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0794], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0461], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0034], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3969e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0591], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0678], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0014], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0218], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0197], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.9181e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.2993e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.8925e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1126], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.9312e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.7337e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0205], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0138], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.8644e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.6729e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "Epoch [1/1], Step [200/8000], Loss: 560568.5000\n",
      "tensor([0.0234], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0513], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.3495e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.0046e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0546], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0383], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0012], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0020], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0606], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0175], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.7349e-189], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0013], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.6633e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0556], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0029], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.7516e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1626], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.7231e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0943e-11], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.2819e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.7834e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3607e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.2493e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0014], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0459], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0013], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0680], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0076], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.7016e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0023], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0499], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0060], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.3689e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0031], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.5302e-26], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0193], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0001], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0284], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0034], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0015], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0410], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.7028e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0183], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0458], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0021], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0043], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0011], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0009], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.1149e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.8459e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0082], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0116], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.0477e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0078], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0086], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.7152e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0639e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1461], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0097], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0025], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.1396e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0039], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0070], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0037], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.6780e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1217], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0124], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0006], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0036], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0038], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0048], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0001], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0469], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0012], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0009], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0271], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.2428e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0529], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1058], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0645], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0044], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.3910e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0105], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0625], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.3471e-14], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.1467e-11], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0652], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0021], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0066], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "Epoch [1/1], Step [300/8000], Loss: 238412.4934\n",
      "tensor([2.1462e-96], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0091], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0269], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0896], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1954], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0011], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3028e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.2874e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.1984e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0021], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3676e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1270], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0062], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.0505e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0006], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0064], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0022], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0663], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.2007e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0016], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0339], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0623], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0053], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.4483e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0559], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0031], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0286], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0765], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0569], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0029], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0053], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0920], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0046], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.6007e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0025], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0395], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0037], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3167e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0914], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0583], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.3628e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0449], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.6412e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.5171e-153], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0083], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0216], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0006], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0316], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0054], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.], device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0570], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0023], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.4617e-23], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.0855e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0518], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.2247e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0012], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0117], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0033], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.1439e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.2994e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0021], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0016], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0084], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0011], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0033], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0011], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0848], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0027], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.3009e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0018], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0637], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.0794e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.6181e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0542], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.0241e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0355], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.3747e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0044], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.2016], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0029], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.5931e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0091], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0068], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0406], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.8473e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0537], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0454], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0035], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0080], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3853e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0722], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "Epoch [1/1], Step [400/8000], Loss: 207677.4996\n",
      "tensor([0.0093], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0227], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.6784e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.6481e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0544], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0269], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0546], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0046], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.5905e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0014], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.3871e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0067], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0013], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0580], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0878], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.4048e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.7731e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0425], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0623], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.6348e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0017], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0604], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0036], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0101], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.6594e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0808], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0024], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0006], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0207], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.1781e-180], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0496], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0182], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.9537e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.4438e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.1306e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0025], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0019], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0238], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1664], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1548], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.0105e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.8002e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.0051e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0548], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.0216e-06], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0166], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.6961e-11], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.6648e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0729], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0020], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0018], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.9182e-11], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0937], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.0410e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.6452e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0100], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0220], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0168], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0100], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0007], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.5582e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0021], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0077], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0337], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.6752e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3644e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0019], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0012], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0442], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0519], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0009], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0055], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.7451e-24], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.7312e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.8050e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0025], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0101], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0030], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0053], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0086], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0012], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0094], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.0329e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.1344e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.6850e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.9729e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0204], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0112], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "Epoch [1/1], Step [500/8000], Loss: 319796.4888\n",
      "tensor([0.0044], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.8415e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0006], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0043], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.2165e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1249], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0051], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0550], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0153], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0653], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0125], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0501], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0148], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0055], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0018], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0066], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0848], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1097], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.5818e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0545], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1497], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.2976e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0318], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0126], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0001], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0664], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.8253e-11], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0294], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.4541e-91], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0122], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0028], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.6834e-13], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0368], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1973], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0926], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.2780e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1188], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0088], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0027], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0015], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.2499e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.4484e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0021], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.2367e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.3297e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0492], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0071], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.5397e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0088], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0027], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0701], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0177], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.8161e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1928], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0069], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0202], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0591], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.7435e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0317], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0042], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0418], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0657], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0066], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0784], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0037], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0474], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0057], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0590], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0033], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.7189e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.7668e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.5306e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.4261e-300], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0615], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0587], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.5769e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3090e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.9171e-145], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0244], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0697], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0104], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0068], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0392], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0007], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.5343e-22], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0944], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0027], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0546], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0044], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0014], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0949], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0043], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "Epoch [1/1], Step [600/8000], Loss: 3680539.4997\n",
      "tensor([0.0557], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0009], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.9808e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0105], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0121], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0076], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.8755e-11], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.1621e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0097], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0007], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0521], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.2255e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0015], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0474], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0272], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0006], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0784], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.8551e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0068], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0011], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0022], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0026], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0124], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.8680e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.5806e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.8772e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0584], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0137], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0903], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0179], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0559], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0319], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.4311e-19], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0085], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0055], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0636], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.0199e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0740], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.4471e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0632e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0610], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.0827e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.5052e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0019], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.1645e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.2108e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0015], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0119], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.1539e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0030], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.7529e-19], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0046], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.4035e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0024], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0082], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0828], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0033], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0046], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0248], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0027], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0014], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0251], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0853], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0673], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0546], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.2591e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0155], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0308], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1570], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.5022e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0029], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.1471e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.8942e-170], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0593], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1708], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.5185e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0603], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.5831e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0267], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0349e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0392e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0009], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.5904e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.5789e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0135], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0031], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0028], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.1469e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0940], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0122], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "Epoch [1/1], Step [700/8000], Loss: 34967.4878\n",
      "tensor([3.2213e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.4442e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0136], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0027], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.5493e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0011], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0038], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0009], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0006], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0006], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0101], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0026], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.9885e-23], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.3127e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.2290e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0480], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0553], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0074], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0366], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0403], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.2729e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0030], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.6814e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0012], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.8188e-06], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0149], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.5690e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0228], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.1653e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0050], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0039], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0203], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.6742e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0009], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0537], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.5379e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0069], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0056], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0016], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0017], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0162], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0111], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.8041e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0026], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1286], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1140], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0178], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.5909e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1531], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0026], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.9052e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0276], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0152], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0092], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0066], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0070], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0876], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0682], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.7004e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3058e-86], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0166], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.9645e-13], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0039], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0399], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0034], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1993], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0958], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0118], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0573], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.0087e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1222], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.2688e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0478e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0019], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.5475e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0082], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0227], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0122], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0034], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.2976e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0089], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0029], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.2003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.1291e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0221], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0625], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0802], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0057], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0351], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0410], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0083], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0436], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0048], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0069], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0500], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "Epoch [1/1], Step [800/8000], Loss: 6246.4500\n",
      "tensor([0.0577], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0116], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.1267e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0147], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0037], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0112], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.7149e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0086], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.7044e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0023], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0041], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0120], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0120], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0074], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.2711e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0046], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0152], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.1437e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1115], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0019], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0018], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0018], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0894], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0023], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0768], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0412], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0004], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0030], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0247], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0562], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0001], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0516], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0803], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.2161e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0166], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0009], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0302], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.0557e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0088], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0010], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0190], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0035], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0112], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0068], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0034], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0051], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0112], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0485], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0017], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0023], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0497], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0820], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0364], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.0307e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0940], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0021], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0169], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0931], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.5585e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.5923e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.9611e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.4954e-18], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0007], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0007], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0001], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0673], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0633], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0210], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.7822e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0530], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.5738e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0385], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0644], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.2720e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.1104e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0001], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0041], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.1648e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0557], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0001], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0029], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0022], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0001], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0927e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0848], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0036], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0112], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0058], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0060], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0964], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.0381e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0016], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0307], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "Epoch [1/1], Step [900/8000], Loss: 694374.4693\n",
      "tensor([3.1361e-18], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0007], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.4044e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.3483e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0351], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0031], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0603], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0196], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.1530e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0383], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1593], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.4667e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0045], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.1504e-12], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.8776e-159], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0645], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0077], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1754], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0245], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0147], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.1223e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0834], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0328], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.4773e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.1431e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0650], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.8706e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.0420e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.2815e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0048], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([6.9187e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0972], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0043], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0170], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0441], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0034], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0187], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.3376e-09], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.3353e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0877], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0018], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0015], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0034], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0134], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0523], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0009], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0015], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.8619e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0592], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0437], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0102], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.6746e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0050], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.1969e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.9414e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0441], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0912], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.9284e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.3949e-21], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([8.2512e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0350], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0422e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.0217e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0037], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0256], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0279], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0038], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0207], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0038], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0022], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0061], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0013], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.1752e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0090], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0072], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0582], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.4248e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.1157e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0218], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0146], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0099], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1191], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1327], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0219], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0031], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.1571], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0188], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.4026e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([7.2930e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0007], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0134], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0103], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0054], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0380], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0906], device='cuda:0', dtype=torch.float64,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0003], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0704], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "Epoch [1/1], Step [1000/8000], Loss: 108296.4296\n",
      "tensor([0.0301], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0262], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0108], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0036], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([3.8979e-08], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0145], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0030], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0013], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0013], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.6910e-12], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0925], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0090], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([2.2735e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.4564e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0138], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0008], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0602], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0450], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([5.4708e-06], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0035], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0446], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0006], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0146], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0186], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0054], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0101], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0740], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0285], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0197], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0062], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0026], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([9.1600e-10], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0024], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0140], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0016], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1.4595e-07], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0002], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0803], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0266], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([4.3975e-05], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0006], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0028], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0038], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0012], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0048], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0005], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0206], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0610], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0029], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0529], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0449], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0015], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0.0130], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-0fbdbe5df729>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Forward pass/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m#print(outputs, label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-fcf8c4d5c44c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__convertor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misatty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ansi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_plain_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = len(df_features.iloc[0])\n",
    "output_size = len(df_label.columns)\n",
    "hidden_size = int(np.ceil((input_size+output_size)/2))\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (feature, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        #print(feature, labels)\n",
    "        feature = torch.tensor(feature,  dtype = torch.float64).to(device)\n",
    "        label = torch.tensor(labels,  dtype = torch.float64).to(device)\n",
    "\n",
    "        # Forward pass/\n",
    "        outputs = model(feature)\n",
    "        #print(outputs, label)\n",
    "        loss = criterion(outputs, label)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for images, labels in test_loader:\n",
    "#         images = images.reshape(-1, 28*28).to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (feature, labels) in enumerate(train_loader):  \n",
    "    if(i >10):\n",
    "        break\n",
    "    print((type(feature)))\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
