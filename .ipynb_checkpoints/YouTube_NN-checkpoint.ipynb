{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as dt\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and Hyperparameters #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./US_length.csv\"\n",
    "learning_rate = 0.00001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "split = 0.8\n",
    "batch_size = 100\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChuckDaddy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_main = pd.read_csv(data_path, sep = ',')\n",
    "#subset data for testing ,use the first 10000\n",
    "df = df_main[:10000]\n",
    "secs = df['sec'].values\n",
    "mins = df['min'].values\n",
    "hours = df['hour'].values\n",
    "total_time = [s+60*m+3600*h for s,m,h in zip(secs, mins, hours)]\n",
    "df['total_time'] = total_time\n",
    "df_features=df[['title', 'total_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChuckDaddy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ChuckDaddy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\ChuckDaddy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_features['title_upper_count'] = df_features['title'].str.findall(r'[A-Z]').str.len()\n",
    "df_features['tag_count'] = [len(s.split('|')) for s in df['tags'].values]\n",
    "df_features['category_id'] = df_main['category_id']\n",
    "df_label = pd.DataFrame()\n",
    "df_label['views'] = df['views']\n",
    "df_features = df_features.drop(columns = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_time</th>\n",
       "      <th>title_upper_count</th>\n",
       "      <th>tag_count</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>678</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1431</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>569</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>430</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_time  title_upper_count  tag_count  category_id\n",
       "0         678                 28          1           22\n",
       "1        1431                 11          4           24\n",
       "2         569                  8         23           23\n",
       "3         430                  4         27           24\n",
       "4         733                 12         14           24"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>748374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2418783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3191434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2095731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     views\n",
       "0   748374\n",
       "1  2418783\n",
       "2  3191434\n",
       "3   343168\n",
       "4  2095731"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Dataloader #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_split = int(len(df_features)*split)\n",
    "train_set = df_features[:tv_split]\n",
    "train_label = df_label[:tv_split]\n",
    "validation_set = df_features[tv_split:]\n",
    "validation_label = df_label[tv_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(dt.Dataset):\n",
    "    def __init__(self, feature, labels):\n",
    "        self.labels = labels\n",
    "        self.feature = feature\n",
    "    def __len__(self):\n",
    "        return(len(self.feature))\n",
    "    def __getitem__(self, idx):\n",
    "        cur_feature = self.feature.iloc[idx]\n",
    "        cur_feature = np.array(cur_feature)\n",
    "        cur_label = self.labels.iloc[idx]\n",
    "        cur_label = np.array(cur_label)\n",
    "        sample = (cur_feature, cur_label)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Dataset(train_set, train_label)\n",
    "test_loader = Dataset(validation_set, validation_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size).double() \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes).double()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/8000], Loss: 38292619224.9929\n",
      "Epoch [1/1], Step [200/8000], Loss: 314237603761.0000\n",
      "Epoch [1/1], Step [300/8000], Loss: 56840758568.9998\n",
      "Epoch [1/1], Step [400/8000], Loss: 43130151684.0000\n",
      "Epoch [1/1], Step [500/8000], Loss: 102270121208.9994\n",
      "Epoch [1/1], Step [600/8000], Loss: 13546374691600.0000\n",
      "Epoch [1/1], Step [700/8000], Loss: 1222761022.8561\n",
      "Epoch [1/1], Step [800/8000], Loss: 39024980.9099\n",
      "Epoch [1/1], Step [900/8000], Loss: 482156640615.7137\n",
      "Epoch [1/1], Step [1000/8000], Loss: 11728144493.9509\n",
      "Epoch [1/1], Step [1100/8000], Loss: 1176009849.0000\n",
      "Epoch [1/1], Step [1200/8000], Loss: 12338099929.0000\n",
      "Epoch [1/1], Step [1300/8000], Loss: 2822371792.1150\n",
      "Epoch [1/1], Step [1400/8000], Loss: 834058439824.0000\n",
      "Epoch [1/1], Step [1500/8000], Loss: 7027804123.7329\n",
      "Epoch [1/1], Step [1600/8000], Loss: 35557265.0928\n",
      "Epoch [1/1], Step [1700/8000], Loss: 109297021201.0000\n",
      "Epoch [1/1], Step [1800/8000], Loss: 9507781073961.0000\n",
      "Epoch [1/1], Step [1900/8000], Loss: 399995118943351.7500\n",
      "Epoch [1/1], Step [2000/8000], Loss: 17891202564.0000\n",
      "Epoch [1/1], Step [2100/8000], Loss: 1872463824400.0000\n",
      "Epoch [1/1], Step [2200/8000], Loss: 4132361218041.0000\n",
      "Epoch [1/1], Step [2300/8000], Loss: 105732656.6607\n",
      "Epoch [1/1], Step [2400/8000], Loss: 25450459023.9956\n",
      "Epoch [1/1], Step [2500/8000], Loss: 12673465.2960\n",
      "Epoch [1/1], Step [2600/8000], Loss: 26718560.9646\n",
      "Epoch [1/1], Step [2700/8000], Loss: 3860417203827.5063\n",
      "Epoch [1/1], Step [2800/8000], Loss: 32439637.0594\n",
      "Epoch [1/1], Step [2900/8000], Loss: 310479341939776.0000\n",
      "Epoch [1/1], Step [3000/8000], Loss: 25403259451.7617\n",
      "Epoch [1/1], Step [3100/8000], Loss: 1448958690529.0000\n",
      "Epoch [1/1], Step [3200/8000], Loss: 351007666681.0000\n",
      "Epoch [1/1], Step [3300/8000], Loss: 17482657283.8874\n",
      "Epoch [1/1], Step [3400/8000], Loss: 81474280969.0000\n",
      "Epoch [1/1], Step [3500/8000], Loss: 3176336881.0000\n",
      "Epoch [1/1], Step [3600/8000], Loss: 557547449362.7013\n",
      "Epoch [1/1], Step [3700/8000], Loss: 91384080803.7770\n",
      "Epoch [1/1], Step [3800/8000], Loss: 590818210608.9110\n",
      "Epoch [1/1], Step [3900/8000], Loss: 188987564499.1696\n",
      "Epoch [1/1], Step [4000/8000], Loss: 96793787689.0000\n",
      "Epoch [1/1], Step [4100/8000], Loss: 218405740921.0000\n",
      "Epoch [1/1], Step [4200/8000], Loss: 285466485710.6049\n",
      "Epoch [1/1], Step [4300/8000], Loss: 1423225140100.0000\n",
      "Epoch [1/1], Step [4400/8000], Loss: 15303744.0000\n",
      "Epoch [1/1], Step [4500/8000], Loss: 1914016910287.0518\n",
      "Epoch [1/1], Step [4600/8000], Loss: 6939056601.0000\n",
      "Epoch [1/1], Step [4700/8000], Loss: 161102957857956.0000\n",
      "Epoch [1/1], Step [4800/8000], Loss: 7976454720.9211\n",
      "Epoch [1/1], Step [4900/8000], Loss: 2743322621.3411\n",
      "Epoch [1/1], Step [5000/8000], Loss: 63170790244.0000\n",
      "Epoch [1/1], Step [5100/8000], Loss: 96275343.9996\n",
      "Epoch [1/1], Step [5200/8000], Loss: 66349517055.5621\n",
      "Epoch [1/1], Step [5300/8000], Loss: 7088798024.9999\n",
      "Epoch [1/1], Step [5400/8000], Loss: 25359925503.9941\n",
      "Epoch [1/1], Step [5500/8000], Loss: 728933458176.0000\n",
      "Epoch [1/1], Step [5600/8000], Loss: 1870195737601.0000\n",
      "Epoch [1/1], Step [5700/8000], Loss: 15733246078824168.0000\n",
      "Epoch [1/1], Step [5800/8000], Loss: 1893742033688.9968\n",
      "Epoch [1/1], Step [5900/8000], Loss: 520159219.5939\n",
      "Epoch [1/1], Step [6000/8000], Loss: 1023360099.9984\n",
      "Epoch [1/1], Step [6100/8000], Loss: 5091964164.0000\n",
      "Epoch [1/1], Step [6200/8000], Loss: 522457187344.0000\n",
      "Epoch [1/1], Step [6300/8000], Loss: 383180609.6008\n",
      "Epoch [1/1], Step [6400/8000], Loss: 7405702280963.6172\n",
      "Epoch [1/1], Step [6500/8000], Loss: 198175115429.3241\n",
      "Epoch [1/1], Step [6600/8000], Loss: 7998364547044.0000\n",
      "Epoch [1/1], Step [6700/8000], Loss: 45658287684.0000\n",
      "Epoch [1/1], Step [6800/8000], Loss: 8619497066404.0000\n",
      "Epoch [1/1], Step [6900/8000], Loss: 20242744729.0000\n",
      "Epoch [1/1], Step [7000/8000], Loss: 1330498576.0000\n",
      "Epoch [1/1], Step [7100/8000], Loss: 3136224004.0000\n",
      "Epoch [1/1], Step [7200/8000], Loss: 822464212.2723\n",
      "Epoch [1/1], Step [7300/8000], Loss: 331598615716.0000\n",
      "Epoch [1/1], Step [7400/8000], Loss: 213019171600.0000\n",
      "Epoch [1/1], Step [7500/8000], Loss: 494216208.0694\n",
      "Epoch [1/1], Step [7600/8000], Loss: 3624389308353.2334\n",
      "Epoch [1/1], Step [7700/8000], Loss: 39874897969.0000\n",
      "Epoch [1/1], Step [7800/8000], Loss: 7098057551523.8242\n",
      "Epoch [1/1], Step [7900/8000], Loss: 508226409909.2421\n",
      "Epoch [1/1], Step [8000/8000], Loss: 7420116072121.0000\n"
     ]
    }
   ],
   "source": [
    "input_size = len(df_features.iloc[0])\n",
    "output_size = len(df_label.columns)\n",
    "hidden_size = int(np.ceil((input_size+output_size)/2))\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (feature, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        #print(feature, labels)\n",
    "        feature = torch.tensor(feature,  dtype = torch.float64).to(device)\n",
    "        label = torch.tensor(labels,  dtype = torch.float64).to(device)\n",
    "\n",
    "        # Forward pass/\n",
    "        outputs = model(feature)\n",
    "        #print(outputs, label)\n",
    "        loss = criterion(outputs, label)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[748374]\n",
      "<class 'numpy.ndarray'>\n",
      "[2418783]\n",
      "<class 'numpy.ndarray'>\n",
      "[3191434]\n",
      "<class 'numpy.ndarray'>\n",
      "[343168]\n",
      "<class 'numpy.ndarray'>\n",
      "[2095731]\n",
      "<class 'numpy.ndarray'>\n",
      "[119180]\n",
      "<class 'numpy.ndarray'>\n",
      "[2103417]\n",
      "<class 'numpy.ndarray'>\n",
      "[817732]\n",
      "<class 'numpy.ndarray'>\n",
      "[826059]\n",
      "<class 'numpy.ndarray'>\n",
      "[256426]\n",
      "<class 'numpy.ndarray'>\n",
      "[81377]\n"
     ]
    }
   ],
   "source": [
    "# for i, (feature, labels) in enumerate(train_loader):  \n",
    "#     if(i >10):\n",
    "#         break\n",
    "#     print((type(feature)))\n",
    "#     print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
